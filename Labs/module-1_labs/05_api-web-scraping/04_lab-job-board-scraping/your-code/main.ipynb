{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Board Scraping Lab\n",
    "\n",
    "In this lab you will first see a minimal but fully functional code snippet to scrape the LinkedIn Job Search webpage. You will then work on top of the example code and complete several chanllenges.\n",
    "\n",
    "### Some Resources \n",
    "\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    \n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    \n",
    "    # Assemble the full url with parameters\n",
    "\n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords])\n",
    "\n",
    "    # Create a request to get the data from the server \n",
    "    page = requests.get(scrape_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    \n",
    "    for card in soup.select(\"div.result-card__contents\"):\n",
    "        title = card.findChild(\"h3\", recursive=False)\n",
    "        company = card.findChild(\"h4\", recursive=False)\n",
    "        location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "        titles.append(title.string)\n",
    "        companies.append(company.string)\n",
    "        locations.append(location.string)\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "        \n",
    "    \n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analytics Associate, CrossInstall</td>\n",
       "      <td>General Mills</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist (Remote)</td>\n",
       "      <td>Kraken Digital Asset Exchange</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA SCIENTIST I</td>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Scientist Apprenticeship</td>\n",
       "      <td>IBM</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>Sonde Health, Inc.</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Curology</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Chicago</td>\n",
       "      <td>SpiderRock</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist 1</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>San Jose, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Financial Analytics Consultant</td>\n",
       "      <td>Toyota North America</td>\n",
       "      <td>Dallas, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Research Assistant IV Non-Lab (Research Data A...</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Analyst, Data and Analysis</td>\n",
       "      <td>Digitas India</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CapTech Ventures, Inc</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Global Atlantic Financial Group</td>\n",
       "      <td>Des Moines, IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shoe Carnival, Inc.</td>\n",
       "      <td>Columbia, SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quantitative Researcher</td>\n",
       "      <td>Pantera Capital</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PerBlue</td>\n",
       "      <td>Madison, WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fraud Intelligence, Data Operations Analyst</td>\n",
       "      <td>White Ops</td>\n",
       "      <td>New York City Metropolitan Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Developer/Analyst</td>\n",
       "      <td>Thrivent</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Science and Analytics</td>\n",
       "      <td>Thermo Fisher Scientific</td>\n",
       "      <td>Carlsbad, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Renaissance Learning</td>\n",
       "      <td>Madison, WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Analytics Consultant</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UHNW Business Analytics</td>\n",
       "      <td>Mstream</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Analyst, Data and Analysis</td>\n",
       "      <td>Digitas North America</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Aditi Consulting</td>\n",
       "      <td>Chandler, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Koch Industries</td>\n",
       "      <td>Louisville, CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0              Data Analytics Associate, CrossInstall   \n",
       "1                             Data Scientist (Remote)   \n",
       "2                                    DATA SCIENTIST I   \n",
       "3                Junior Data Scientist Apprenticeship   \n",
       "4                               Data Science - Intern   \n",
       "5                                 Data Science Intern   \n",
       "6                              Data Analyst - Chicago   \n",
       "7                                    Data Scientist 1   \n",
       "8                      Financial Analytics Consultant   \n",
       "9   Research Assistant IV Non-Lab (Research Data A...   \n",
       "10                         Analyst, Data and Analysis   \n",
       "11                                       Data Analyst   \n",
       "12                                Data Analyst Intern   \n",
       "13                                       Data Analyst   \n",
       "14                            Quantitative Researcher   \n",
       "15                                       Data Analyst   \n",
       "16        Fraud Intelligence, Data Operations Analyst   \n",
       "17                             Data Developer/Analyst   \n",
       "18                         Data Science and Analytics   \n",
       "19                                       Data Analyst   \n",
       "20                               Analytics Consultant   \n",
       "21                            UHNW Business Analytics   \n",
       "22                         Analyst, Data and Analysis   \n",
       "23                                       Data Analyst   \n",
       "24                                     DATA SCIENTIST   \n",
       "\n",
       "                            Company                         Location  \n",
       "0                     General Mills                San Francisco, CA  \n",
       "1     Kraken Digital Asset Exchange                      Chicago, IL  \n",
       "2                    The Home Depot                      Houston, TX  \n",
       "3                               IBM                     New York, NY  \n",
       "4                Sonde Health, Inc.                       Boston, MA  \n",
       "5                          Curology                San Francisco, CA  \n",
       "6                        SpiderRock                      Chicago, IL  \n",
       "7                            PayPal                     San Jose, CA  \n",
       "8              Toyota North America                       Dallas, TX  \n",
       "9                Harvard University                       Boston, MA  \n",
       "10                    Digitas India                       Boston, MA  \n",
       "11            CapTech Ventures, Inc                    Charlotte, NC  \n",
       "12  Global Atlantic Financial Group                   Des Moines, IA  \n",
       "13              Shoe Carnival, Inc.                     Columbia, SC  \n",
       "14                  Pantera Capital                San Francisco, CA  \n",
       "15                          PerBlue                      Madison, WI  \n",
       "16                        White Ops  New York City Metropolitan Area  \n",
       "17                         Thrivent                  Minneapolis, MN  \n",
       "18         Thermo Fisher Scientific                     Carlsbad, CA  \n",
       "19             Renaissance Learning                      Madison, WI  \n",
       "20                         Deloitte                   Washington, DC  \n",
       "21                          Mstream                     New York, NY  \n",
       "22            Digitas North America                       Boston, MA  \n",
       "23                 Aditi Consulting                     Chandler, AZ  \n",
       "24                  Koch Industries                   Louisville, CO  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to call the function\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "The first challenge for you is to update the `scrape_linkedin_job_search` function by adding a new parameter called `num_pages`. This will allow you to search more than 25 jobs with this function. Suggested steps:\n",
    "\n",
    "1. Go to https://www.linkedin.com/jobs/search/?keywords=data%20analysis in your browser.\n",
    "1. Scroll down the left panel and click the page 2 link. Look at how the URL changes and identify the page offset parameter.\n",
    "1. Add `num_pages` as a new param to the `scrape_linkedin_job_search` function. Update the function code so that it uses a \"for\" loop to retrieve several pages of search results.\n",
    "1. Test your new function by scraping 5 pages of the search results.\n",
    "\n",
    "Hint: Prepare for the case where there are less than 5 pages of search results. Your function should be robust enough to **not** trigger errors. Simply skip making additional searches and return all results if the search already reaches the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analytics Associate, CrossInstall</td>\n",
       "      <td>General Mills</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist (Remote)</td>\n",
       "      <td>Kraken Digital Asset Exchange</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA SCIENTIST I</td>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Scientist Apprenticeship</td>\n",
       "      <td>IBM</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>Sonde Health, Inc.</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Curology</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Chicago</td>\n",
       "      <td>SpiderRock</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Financial Analytics Consultant</td>\n",
       "      <td>Toyota North America</td>\n",
       "      <td>Dallas, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Research Assistant IV Non-Lab (Research Data A...</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analyst, Data and Analysis</td>\n",
       "      <td>Digitas India</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CapTech Ventures, Inc</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Global Atlantic Financial Group</td>\n",
       "      <td>Des Moines, IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shoe Carnival, Inc.</td>\n",
       "      <td>Columbia, SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Quantitative Researcher</td>\n",
       "      <td>Pantera Capital</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PerBlue</td>\n",
       "      <td>Madison, WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fraud Intelligence, Data Operations Analyst</td>\n",
       "      <td>White Ops</td>\n",
       "      <td>New York City Metropolitan Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science and Analytics</td>\n",
       "      <td>Thermo Fisher Scientific</td>\n",
       "      <td>Carlsbad, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UHNW Business Analytics</td>\n",
       "      <td>Mstream</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Analyst, Data and Analysis</td>\n",
       "      <td>Digitas North America</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Junior Data Scientist - Model Governance</td>\n",
       "      <td>Cigna</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Aditi Consulting</td>\n",
       "      <td>Chandler, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Koch Industries</td>\n",
       "      <td>Louisville, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Associate Analyst - Analytics</td>\n",
       "      <td>Barkley</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Massachusetts General Hospital</td>\n",
       "      <td>Charlestown, NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Business Analyst Level-1</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Business Analyst Level-1</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Newark, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Business Analyst Fresher</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Business Analyst Fresher</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Portland, OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Statistical Programmer</td>\n",
       "      <td>Cygnus Professionals Inc.</td>\n",
       "      <td>New Jersey, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Analyst, Data and Analysis</td>\n",
       "      <td>Digitas India</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SAS Developer</td>\n",
       "      <td>QuaXigma</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>IT Analyst</td>\n",
       "      <td>PTE Systems International, LLC</td>\n",
       "      <td>Hialeah, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Entry level Business System Analyst</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Reno, NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Business Analyst Trainee</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Hoboken, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SQL Developer</td>\n",
       "      <td>Optello</td>\n",
       "      <td>Burnsville, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Business Analyst Trainee</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Rock Hill, SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Business Analyst Fresher</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Bowie, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Business Analyst Level-1</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Pasadena, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Business Analyst Level-1</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Aurora, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Associate Business Analyst (Contract) (JR1017367)</td>\n",
       "      <td>Broadridge</td>\n",
       "      <td>Edgewood, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ENTRY LEVEL Business System Analyst</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Lead Analytics Consultant-BI Consultant</td>\n",
       "      <td>Vertiv Inc.</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Process Engineer</td>\n",
       "      <td>Talent Options ~ Diversity Staffing &amp; Recruiti...</td>\n",
       "      <td>San Antonio, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Urgent - Business Analyst</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Newark, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Data Scientist, Combinatorial Optimization</td>\n",
       "      <td>DeVine Consulting, Inc.</td>\n",
       "      <td>Monterey, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Urgent - Business Analyst Fresher</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Portland, OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IT Business Analyst</td>\n",
       "      <td>Optello</td>\n",
       "      <td>Tallahassee, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Urgent - Business Analyst Fresher</td>\n",
       "      <td>Staffigo</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0              Data Analytics Associate, CrossInstall   \n",
       "1                             Data Scientist (Remote)   \n",
       "2                                    DATA SCIENTIST I   \n",
       "3                Junior Data Scientist Apprenticeship   \n",
       "4                               Data Science - Intern   \n",
       "5                                 Data Science Intern   \n",
       "6                              Data Analyst - Chicago   \n",
       "7                      Financial Analytics Consultant   \n",
       "8   Research Assistant IV Non-Lab (Research Data A...   \n",
       "9                          Analyst, Data and Analysis   \n",
       "10                                       Data Analyst   \n",
       "11                                Data Analyst Intern   \n",
       "12                                       Data Analyst   \n",
       "13                            Quantitative Researcher   \n",
       "14                                       Data Analyst   \n",
       "15        Fraud Intelligence, Data Operations Analyst   \n",
       "16                         Data Science and Analytics   \n",
       "17                            UHNW Business Analytics   \n",
       "18                         Analyst, Data and Analysis   \n",
       "19           Junior Data Scientist - Model Governance   \n",
       "20                                       Data Analyst   \n",
       "21                                     DATA SCIENTIST   \n",
       "22                      Associate Analyst - Analytics   \n",
       "23                                     Data Analyst I   \n",
       "24                                     Data Scientist   \n",
       "25                           Business Analyst Level-1   \n",
       "26                           Business Analyst Level-1   \n",
       "27                           Business Analyst Fresher   \n",
       "28                           Business Analyst Fresher   \n",
       "29                             Statistical Programmer   \n",
       "30                         Analyst, Data and Analysis   \n",
       "31                                      SAS Developer   \n",
       "32                                         IT Analyst   \n",
       "33                Entry level Business System Analyst   \n",
       "34                           Business Analyst Trainee   \n",
       "35                                      SQL Developer   \n",
       "36                           Business Analyst Trainee   \n",
       "37                           Business Analyst Fresher   \n",
       "38                           Business Analyst Level-1   \n",
       "39                           Business Analyst Level-1   \n",
       "40  Associate Business Analyst (Contract) (JR1017367)   \n",
       "41                ENTRY LEVEL Business System Analyst   \n",
       "42            Lead Analytics Consultant-BI Consultant   \n",
       "43                                   Process Engineer   \n",
       "44                          Urgent - Business Analyst   \n",
       "45         Data Scientist, Combinatorial Optimization   \n",
       "46                  Urgent - Business Analyst Fresher   \n",
       "47                                IT Business Analyst   \n",
       "48                                   Business Analyst   \n",
       "49                  Urgent - Business Analyst Fresher   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                       General Mills   \n",
       "1                       Kraken Digital Asset Exchange   \n",
       "2                                      The Home Depot   \n",
       "3                                                 IBM   \n",
       "4                                  Sonde Health, Inc.   \n",
       "5                                            Curology   \n",
       "6                                          SpiderRock   \n",
       "7                                Toyota North America   \n",
       "8                                  Harvard University   \n",
       "9                                       Digitas India   \n",
       "10                              CapTech Ventures, Inc   \n",
       "11                    Global Atlantic Financial Group   \n",
       "12                                Shoe Carnival, Inc.   \n",
       "13                                    Pantera Capital   \n",
       "14                                            PerBlue   \n",
       "15                                          White Ops   \n",
       "16                           Thermo Fisher Scientific   \n",
       "17                                            Mstream   \n",
       "18                              Digitas North America   \n",
       "19                                              Cigna   \n",
       "20                                   Aditi Consulting   \n",
       "21                                    Koch Industries   \n",
       "22                                            Barkley   \n",
       "23                     Massachusetts General Hospital   \n",
       "24                                            Datadog   \n",
       "25                                           Staffigo   \n",
       "26                                           Staffigo   \n",
       "27                                           Staffigo   \n",
       "28                                           Staffigo   \n",
       "29                         Cygnus Professionals Inc.    \n",
       "30                                      Digitas India   \n",
       "31                                           QuaXigma   \n",
       "32                     PTE Systems International, LLC   \n",
       "33                                           Staffigo   \n",
       "34                                           Staffigo   \n",
       "35                                            Optello   \n",
       "36                                           Staffigo   \n",
       "37                                           Staffigo   \n",
       "38                                           Staffigo   \n",
       "39                                           Staffigo   \n",
       "40                                         Broadridge   \n",
       "41                                           Staffigo   \n",
       "42                                        Vertiv Inc.   \n",
       "43  Talent Options ~ Diversity Staffing & Recruiti...   \n",
       "44                                           Staffigo   \n",
       "45                            DeVine Consulting, Inc.   \n",
       "46                                           Staffigo   \n",
       "47                                            Optello   \n",
       "48                                           Staffigo   \n",
       "49                                           Staffigo   \n",
       "\n",
       "                           Location  \n",
       "0                 San Francisco, CA  \n",
       "1                       Chicago, IL  \n",
       "2                       Houston, TX  \n",
       "3                      New York, NY  \n",
       "4                        Boston, MA  \n",
       "5                 San Francisco, CA  \n",
       "6                       Chicago, IL  \n",
       "7                        Dallas, TX  \n",
       "8                        Boston, MA  \n",
       "9                        Boston, MA  \n",
       "10                    Charlotte, NC  \n",
       "11                   Des Moines, IA  \n",
       "12                     Columbia, SC  \n",
       "13                San Francisco, CA  \n",
       "14                      Madison, WI  \n",
       "15  New York City Metropolitan Area  \n",
       "16                     Carlsbad, CA  \n",
       "17                     New York, NY  \n",
       "18                       Boston, MA  \n",
       "19                     New York, NY  \n",
       "20                     Chandler, AZ  \n",
       "21                   Louisville, CO  \n",
       "22                  Kansas City, KS  \n",
       "23                  Charlestown, NH  \n",
       "24                     New York, NY  \n",
       "25                  Santa Clara, CA  \n",
       "26                       Newark, NJ  \n",
       "27                  Santa Clara, CA  \n",
       "28                     Portland, OR  \n",
       "29        New Jersey, United States  \n",
       "30                       Boston, MA  \n",
       "31                   Schaumburg, IL  \n",
       "32                      Hialeah, FL  \n",
       "33                         Reno, NV  \n",
       "34                      Hoboken, NJ  \n",
       "35                   Burnsville, MN  \n",
       "36                    Rock Hill, SC  \n",
       "37                        Bowie, MD  \n",
       "38                     Pasadena, CA  \n",
       "39                       Aurora, CO  \n",
       "40                     Edgewood, NY  \n",
       "41                       Denver, CO  \n",
       "42                    Princeton, NJ  \n",
       "43                  San Antonio, FL  \n",
       "44                       Newark, NJ  \n",
       "45                     Monterey, CA  \n",
       "46                     Portland, OR  \n",
       "47                  Tallahassee, FL  \n",
       "48                      Seattle, WA  \n",
       "49                      Chicago, IL  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords, n):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    \n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    \n",
    "        \n",
    "    # Assemble the full url with parameters\n",
    "    for i in list(range(n)):\n",
    "            \n",
    "        scrape_url = ''.join([BASE_URL, 'keywords=', keywords,'&start=',str((i)*25)])\n",
    "    \n",
    "        # Create a request to get the data from the server \n",
    "        page = requests.get(scrape_url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        \n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "         \n",
    "    \n",
    "\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis',2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Further improve your function so that it can search jobs in a specific country. Add the 3rd param to your function called `country`. The steps are identical to those in Challange 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Junior) Data Analyst *</td>\n",
       "      <td>myToys.de G.m.b.H</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Intern</td>\n",
       "      <td>Pandata</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Jam City</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst (m/f/x)</td>\n",
       "      <td>Audible, Inc.</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst (f/m/x)</td>\n",
       "      <td>audibene</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PeopleDoc Inc.</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist, Pricing</td>\n",
       "      <td>SHARE NOW</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Junior) Data Analyst - Marketing</td>\n",
       "      <td>Trade Republic</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>FY International</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Junior) Data Scientist / Data Analyst (w/m/d)</td>\n",
       "      <td>KPMG Deutschland</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>hundred</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Moyyn</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Global Quality Analysis and Operations-Team Le...</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Revenue Data Analyst (m/f/d)</td>\n",
       "      <td>Pepper.com - The World's Largest Deal Community</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>plista</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Analyst / Engineer (m/w/d)</td>\n",
       "      <td>Enote</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Opinary</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Scientist - Operations</td>\n",
       "      <td>The Adecco Group</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Kraken Digital Asset Exchange</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>Bankpower GmbH</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Consultant/Analyst/Scientist (m/w/d), Berlin</td>\n",
       "      <td>9 friendly white rabbits</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Product Analyst</td>\n",
       "      <td>AMBOSS</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Analyst (m/f/d)</td>\n",
       "      <td>Doodle Inc.</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Scientist* / Data Analyst* - Big Data</td>\n",
       "      <td>IAV GmbH Ingenieurgesellschaft Auto und Verkehr</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Team Lead Data Products and Analytics - New Bu...</td>\n",
       "      <td>idealo internet GmbH</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Software Engineer - Data Platform</td>\n",
       "      <td>Advertima</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Senior Data Engineer Marketing Services</td>\n",
       "      <td>Zalando</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Senior Product Manager, Booking &amp; Payments (m ...</td>\n",
       "      <td>Omio</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Senior Software Engineer - data</td>\n",
       "      <td>Pleo</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Revenue Data Analyst (m/f/d)</td>\n",
       "      <td>Pepper.com - The World's Largest Deal Community</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(Senior) Marketing Analyst (m/f/d)</td>\n",
       "      <td>Mister Spex GmbH</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Senior Data Scientist @ wattx</td>\n",
       "      <td>wattx</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Analytics Consultant</td>\n",
       "      <td>Green Expert Technology Inc.</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Data Analyst (m|f|x) - New Business</td>\n",
       "      <td>idealo internet</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Analyst Sales &amp; Markets Lounge</td>\n",
       "      <td>Zalando</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Senior Product Analyst</td>\n",
       "      <td>AMBOSS</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Amazon.com, Inc</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Senior Business Intelligence Manager (m/f/d)</td>\n",
       "      <td>Zalando SE</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Artsy</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>External Manufacturing Digital Project Manager...</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Senior Software Development Engineer - AWS Bil...</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ecotoxicologist Specialist Data Analysis and B...</td>\n",
       "      <td>BASF</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Financial Planning Analyst</td>\n",
       "      <td>Contentful</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Software Engineer - Data Platform</td>\n",
       "      <td>Advertima</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Business Intelligence Analyst (f/m/x)</td>\n",
       "      <td>AUTO1 GROUP</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Senior Project Manager/ Program Manager</td>\n",
       "      <td>Publicis Emil</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Senior Data Engineer (Scoober)</td>\n",
       "      <td>Takeaway.com</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Data Scientist  Operations</td>\n",
       "      <td>The Adecco Group</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>EMEA Sales Operation Analyst</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(Senior) Data Product Manager - Ad Tech (f/m/d)</td>\n",
       "      <td>Delivery Hero</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                             (Junior) Data Analyst *   \n",
       "1                                         Data Intern   \n",
       "2                                        Data Analyst   \n",
       "3                                Data Analyst (m/f/x)   \n",
       "4                                Data Analyst (f/m/x)   \n",
       "5                                        Data Analyst   \n",
       "6                             Data Scientist, Pricing   \n",
       "7                   (Junior) Data Analyst - Marketing   \n",
       "8                                        Data Analyst   \n",
       "9      (Junior) Data Scientist / Data Analyst (w/m/d)   \n",
       "10                                     Data Scientist   \n",
       "11                                       Data Analyst   \n",
       "12  Global Quality Analysis and Operations-Team Le...   \n",
       "13                       Revenue Data Analyst (m/f/d)   \n",
       "14                               Data Analyst (m/w/d)   \n",
       "15                    Data Analyst / Engineer (m/w/d)   \n",
       "16                                     Data Scientist   \n",
       "17                        Data Scientist - Operations   \n",
       "18                                       Data Analyst   \n",
       "19                               Data Analyst (m/w/d)   \n",
       "20  Data Consultant/Analyst/Scientist (m/w/d), Berlin   \n",
       "21                                    Product Analyst   \n",
       "22                               Data Analyst (m/f/d)   \n",
       "23         Data Scientist* / Data Analyst* - Big Data   \n",
       "24  Team Lead Data Products and Analytics - New Bu...   \n",
       "25                  Software Engineer - Data Platform   \n",
       "26            Senior Data Engineer Marketing Services   \n",
       "27  Senior Product Manager, Booking & Payments (m ...   \n",
       "28                    Senior Software Engineer - data   \n",
       "29                       Revenue Data Analyst (m/f/d)   \n",
       "30                 (Senior) Marketing Analyst (m/f/d)   \n",
       "31                      Senior Data Scientist @ wattx   \n",
       "32                          Data Analytics Consultant   \n",
       "33                Data Analyst (m|f|x) - New Business   \n",
       "34                Data Analyst Sales & Markets Lounge   \n",
       "35                             Senior Product Analyst   \n",
       "36                                  Sr Data Scientist   \n",
       "37       Senior Business Intelligence Manager (m/f/d)   \n",
       "38                                 Lead Data Engineer   \n",
       "39  External Manufacturing Digital Project Manager...   \n",
       "40  Senior Software Development Engineer - AWS Bil...   \n",
       "41  Ecotoxicologist Specialist Data Analysis and B...   \n",
       "42                         Financial Planning Analyst   \n",
       "43                  Software Engineer - Data Platform   \n",
       "44              Business Intelligence Analyst (f/m/x)   \n",
       "45            Senior Project Manager/ Program Manager   \n",
       "46                     Senior Data Engineer (Scoober)   \n",
       "47                        Data Scientist  Operations   \n",
       "48                       EMEA Sales Operation Analyst   \n",
       "49    (Senior) Data Product Manager - Ad Tech (f/m/d)   \n",
       "\n",
       "                                            Company                 Location  \n",
       "0                                 myToys.de G.m.b.H  Berlin, Berlin, Germany  \n",
       "1                                           Pandata  Berlin, Berlin, Germany  \n",
       "2                                          Jam City  Berlin, Berlin, Germany  \n",
       "3                                     Audible, Inc.  Berlin, Berlin, Germany  \n",
       "4                                          audibene  Berlin, Berlin, Germany  \n",
       "5                                    PeopleDoc Inc.  Berlin, Berlin, Germany  \n",
       "6                                         SHARE NOW          Berlin, Germany  \n",
       "7                                    Trade Republic  Berlin, Berlin, Germany  \n",
       "8                                  FY International  Berlin, Berlin, Germany  \n",
       "9                                  KPMG Deutschland  Berlin, Berlin, Germany  \n",
       "10                                          hundred  Berlin, Berlin, Germany  \n",
       "11                                            Moyyn  Berlin, Berlin, Germany  \n",
       "12                                           TikTok          Berlin, Germany  \n",
       "13  Pepper.com - The World's Largest Deal Community          Berlin, Germany  \n",
       "14                                           plista  Berlin, Berlin, Germany  \n",
       "15                                            Enote  Berlin, Berlin, Germany  \n",
       "16                                          Opinary  Berlin, Berlin, Germany  \n",
       "17                                 The Adecco Group  Berlin, Berlin, Germany  \n",
       "18                    Kraken Digital Asset Exchange          Berlin, Germany  \n",
       "19                                   Bankpower GmbH  Berlin, Berlin, Germany  \n",
       "20                         9 friendly white rabbits  Berlin, Berlin, Germany  \n",
       "21                                           AMBOSS  Berlin, Berlin, Germany  \n",
       "22                                      Doodle Inc.  Berlin, Berlin, Germany  \n",
       "23  IAV GmbH Ingenieurgesellschaft Auto und Verkehr  Berlin, Berlin, Germany  \n",
       "24                             idealo internet GmbH  Berlin, Berlin, Germany  \n",
       "25                                        Advertima  Berlin, Berlin, Germany  \n",
       "26                                          Zalando  Berlin, Berlin, Germany  \n",
       "27                                             Omio  Berlin, Berlin, Germany  \n",
       "28                                             Pleo  Berlin, Berlin, Germany  \n",
       "29  Pepper.com - The World's Largest Deal Community          Berlin, Germany  \n",
       "30                                 Mister Spex GmbH  Berlin, Berlin, Germany  \n",
       "31                                            wattx  Berlin, Berlin, Germany  \n",
       "32                     Green Expert Technology Inc.  Berlin, Berlin, Germany  \n",
       "33                                  idealo internet  Berlin, Berlin, Germany  \n",
       "34                                          Zalando  Berlin, Berlin, Germany  \n",
       "35                                           AMBOSS  Berlin, Berlin, Germany  \n",
       "36                                  Amazon.com, Inc  Berlin, Berlin, Germany  \n",
       "37                                       Zalando SE  Berlin, Berlin, Germany  \n",
       "38                                            Artsy  Berlin, Berlin, Germany  \n",
       "39                                            Bayer  Berlin, Berlin, Germany  \n",
       "40                        Amazon Web Services (AWS)  Berlin, Berlin, Germany  \n",
       "41                                             BASF  Berlin, Berlin, Germany  \n",
       "42                                       Contentful          Berlin, Germany  \n",
       "43                                        Advertima          Berlin, Germany  \n",
       "44                                      AUTO1 GROUP  Berlin, Berlin, Germany  \n",
       "45                                    Publicis Emil  Berlin, Berlin, Germany  \n",
       "46                                     Takeaway.com  Berlin, Berlin, Germany  \n",
       "47                                 The Adecco Group  Berlin, Berlin, Germany  \n",
       "48                        Amazon Web Services (AWS)  Berlin, Berlin, Germany  \n",
       "49                                    Delivery Hero  Berlin, Berlin, Germany  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "# your code here\n",
    "\n",
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords, country, n):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    \n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    \n",
    "        \n",
    "    # Assemble the full url with parameters\n",
    "    for i in list(range(n)):\n",
    "            \n",
    "        scrape_url = ''.join([BASE_URL, 'keywords=', keywords,'&location=', country, '&start=',str((i)*25)])\n",
    "    \n",
    "        # Create a request to get the data from the server \n",
    "        page = requests.get(scrape_url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        \n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "         \n",
    "    \n",
    "\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis','Berlin%2C%20Germany',2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "Add the 4th param called `num_days` to your function to allow it to search jobs posted in the past X days. Note that in the LinkedIn job search the searched timespan is specified with the following param:\n",
    "\n",
    "```\n",
    "f_TPR=r259200\n",
    "```\n",
    "\n",
    "The number part in the param value is the number of seconds. 259,200 seconds equal to 3 days. You need to convert `num_days` to number of seconds and supply that info to LinkedIn job search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Copywriter &amp; Social Media Editor DE - B...</td>\n",
       "      <td>Marley Spoon</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private Equity Internship</td>\n",
       "      <td>NORD Holding Unternehmensbeteiligungsgesellsch...</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intern Investment Analyst (m/w/d)</td>\n",
       "      <td>LIQID</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Build the Future - Graduate Program</td>\n",
       "      <td>Prysmian Group</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Copywriter (Freelance)</td>\n",
       "      <td>Paintgun.io</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intern Commercial Planning Intern (M/F/D)</td>\n",
       "      <td>Zalando SE</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intern Entrepreneur in Residence (m/f/d) - Berlin</td>\n",
       "      <td>Campusjger</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Graduate Analyst (m/f/x), Performance Marketin...</td>\n",
       "      <td>Wayfair</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Intern Business Development (m/f/d)</td>\n",
       "      <td>Magaloop</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Administrative Assistant</td>\n",
       "      <td>KKA Partners</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Growth Manager for France | High...</td>\n",
       "      <td>Consultport</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Junior Marketing Creatives Manager (f/m/d)</td>\n",
       "      <td>Kolibri Games</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Junior Recruiter (f/x/m)</td>\n",
       "      <td>OUTFITTERY</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>International Product Manager RX (m/f/d)</td>\n",
       "      <td>BERLIN-CHEMIE</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Operations Analyst</td>\n",
       "      <td>Trade Republic</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Managing Director Germany</td>\n",
       "      <td>Atlantic Labs</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Product Analyst</td>\n",
       "      <td>AMBOSS</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Strategy Consultant (all genders) Healthcare &amp;...</td>\n",
       "      <td>Accenture DACH</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SOCIAL MEDIA EDITOR</td>\n",
       "      <td>Guesstimate</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Financial Analyst (Operations)</td>\n",
       "      <td>Point Nine Capital</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Junior Controller Intercompany (m/f/d)</td>\n",
       "      <td>BASF</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Head of Investing</td>\n",
       "      <td>Yova Impact Investing</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Paid Internship Influencer Marketing Poland (*)</td>\n",
       "      <td>Oceans Apart</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Co-Founder, Lead Product Manager (f/m/x)</td>\n",
       "      <td>Product People</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Content Editor (FR)</td>\n",
       "      <td>OneFootball</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Junior Copywriter & Social Media Editor DE - B...   \n",
       "1                           Private Equity Internship   \n",
       "2                   Intern Investment Analyst (m/w/d)   \n",
       "3                 Build the Future - Graduate Program   \n",
       "4                              Copywriter (Freelance)   \n",
       "5           Intern Commercial Planning Intern (M/F/D)   \n",
       "6   Intern Entrepreneur in Residence (m/f/d) - Berlin   \n",
       "7   Graduate Analyst (m/f/x), Performance Marketin...   \n",
       "8                 Intern Business Development (m/f/d)   \n",
       "9                            Administrative Assistant   \n",
       "10  International Growth Manager for France | High...   \n",
       "11         Junior Marketing Creatives Manager (f/m/d)   \n",
       "12                           Junior Recruiter (f/x/m)   \n",
       "13           International Product Manager RX (m/f/d)   \n",
       "14                                 Operations Analyst   \n",
       "15                          Managing Director Germany   \n",
       "16                                    Product Analyst   \n",
       "17  Strategy Consultant (all genders) Healthcare &...   \n",
       "18                                SOCIAL MEDIA EDITOR   \n",
       "19                     Financial Analyst (Operations)   \n",
       "20             Junior Controller Intercompany (m/f/d)   \n",
       "21                                  Head of Investing   \n",
       "22    Paid Internship Influencer Marketing Poland (*)   \n",
       "23           Co-Founder, Lead Product Manager (f/m/x)   \n",
       "24                                Content Editor (FR)   \n",
       "\n",
       "                                              Company                 Location  \n",
       "0                                        Marley Spoon  Berlin, Berlin, Germany  \n",
       "1   NORD Holding Unternehmensbeteiligungsgesellsch...  Berlin, Berlin, Germany  \n",
       "2                                               LIQID  Berlin, Berlin, Germany  \n",
       "3                                      Prysmian Group          Berlin, Germany  \n",
       "4                                         Paintgun.io  Berlin, Berlin, Germany  \n",
       "5                                          Zalando SE  Berlin, Berlin, Germany  \n",
       "6                                         Campusjger  Berlin, Berlin, Germany  \n",
       "7                                             Wayfair  Berlin, Berlin, Germany  \n",
       "8                                           Magaloop   Berlin, Berlin, Germany  \n",
       "9                                        KKA Partners  Berlin, Berlin, Germany  \n",
       "10                                        Consultport  Berlin, Berlin, Germany  \n",
       "11                                      Kolibri Games  Berlin, Berlin, Germany  \n",
       "12                                         OUTFITTERY          Berlin, Germany  \n",
       "13                                      BERLIN-CHEMIE  Berlin, Berlin, Germany  \n",
       "14                                     Trade Republic  Berlin, Berlin, Germany  \n",
       "15                                      Atlantic Labs          Berlin, Germany  \n",
       "16                                             AMBOSS  Berlin, Berlin, Germany  \n",
       "17                                     Accenture DACH  Berlin, Berlin, Germany  \n",
       "18                                        Guesstimate  Berlin, Berlin, Germany  \n",
       "19                                 Point Nine Capital  Berlin, Berlin, Germany  \n",
       "20                                               BASF  Berlin, Berlin, Germany  \n",
       "21                              Yova Impact Investing  Berlin, Berlin, Germany  \n",
       "22                                       Oceans Apart  Berlin, Berlin, Germany  \n",
       "23                                     Product People          Berlin, Germany  \n",
       "24                                        OneFootball  Berlin, Berlin, Germany  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords, country, num_days, n):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    \n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    num_sec= (num_days*24*60*60)\n",
    "    \n",
    "    # Assemble the full url with parameters\n",
    "    for i in list(range(n)):\n",
    "            \n",
    "        scrape_url = ''.join([BASE_URL,'f_TPR=', str(num_sec) ,'keywords=', keywords,'&location=', country, '&start=',str((i)*25)])\n",
    "    \n",
    "        # Create a request to get the data from the server \n",
    "        page = requests.get(scrape_url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        \n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "         \n",
    "    \n",
    "\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis','Berlin%2C%20Germany', 0.01,1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Allow your function to also retrieve the \"Seniority Level\" of each job searched. Note that the Seniority Level info is not in the initial search results. You need to make a separate search request for each job card based on the `currentJobId` value which you can extract from the job card HTML.\n",
    "\n",
    "After you obtain the Seniority Level info, update the function and add it to a new column of the returned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
